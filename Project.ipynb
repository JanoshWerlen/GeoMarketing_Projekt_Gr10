{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "555aa4e1",
   "metadata": {},
   "source": [
    "# Database Connection Setup\n",
    "This cell sets up the connection to the local PostgreSQL/PostGIS database using SQLAlchemy.\n",
    "\n",
    "**Credentials are now loaded from the `.env` file using `python-dotenv`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362b613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***p***o***s***t***g***r***e***s***q***l***:***/***/***p***o***s***t***g***r***e***s***:***1***7***9***4***6***8***2***3***5***0***.***@***l***o***c***a***l***h***o***s***t***:***5***4***3***2***/***g***e***o***m***a***r***k***e***t***i***n***g***\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "local_db_url = os.getenv('LOCAL_DB_URL')\n",
    "if not local_db_url:\n",
    "    raise ValueError('LOCAL_DB_URL not set in .env')\n",
    "\n",
    "# Create the engine\n",
    "engine = create_engine(local_db_url)\n",
    "print(local_db_url.replace(os.getenv('LOCAL_DB_PASSWORD', ''), '***'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dc124a",
   "metadata": {},
   "source": [
    "# Preparing the Data\n",
    "This section loads the raw Excel data, cleans it by removing columns with too many missing values, imputes missing numeric values by group, removes duplicates, and saves the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e2701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "file_path = 'Data/Export_V2.xlsx'\n",
    "df_raw = pd.read_excel(file_path, sheet_name=0)\n",
    "df_raw.to_sql('raw_data', engine, index=False, if_exists='replace')\n",
    "\n",
    "# Drop columns with more than 50% missing values\n",
    "threshold = len(df_raw) * 0.5\n",
    "df_cleaned = df_raw.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "# Fill numeric columns with the median per BFS_NR group\n",
    "numeric_cols = df_cleaned.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Grouped imputation\n",
    "df_cleaned[numeric_cols] = df_cleaned.groupby('BFS_NR')[numeric_cols].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Remove duplicates (just in case)\n",
    "df_cleaned.drop_duplicates(inplace=True)\n",
    "df_cleaned.to_sql('cleaned_data', engine, index=False, if_exists='replace')\n",
    "\n",
    "# Save the cleaned data\n",
    "df_cleaned.to_excel('Data/Cleaned_Data.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa03e8d9",
   "metadata": {},
   "source": [
    "# Load Cleaned Data to Database\n",
    "This cell loads the cleaned Excel data and uploads it to the database as a new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffa88f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy.sql import text\n",
    "\n",
    "# Drop the materialized view if it exists\n",
    "with engine.connect() as conn:\n",
    "\tconn.execute(text(\"DROP MATERIALIZED VIEW IF EXISTS gemeinden_merged CASCADE\"))\n",
    "\tconn.commit()\n",
    "\n",
    "# Load your cleaned Excel data\n",
    "df = pd.read_excel(\"Data/Cleaned_Data.xlsx\")\n",
    "\n",
    "# Push to SQL\n",
    "df.to_sql(\"gemeinden_cleaned\", engine, index=False, if_exists=\"replace\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe8cb79",
   "metadata": {},
   "source": [
    "# Import and Upload Shapefile\n",
    "This cell loads the municipality boundaries shapefile, converts it to the correct coordinate system, and uploads it to the PostGIS database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77262fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from geoalchemy2 import Geometry\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "\n",
    "# Load shapefile\n",
    "gdf = gpd.read_file(\"Gemeindegrenzen/UP_GEMEINDEN_F.shp\")\n",
    "\n",
    "# Convert to WGS84 for Leaflet\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Connect to DB\n",
    "engine = create_engine(local_db_url)\n",
    "\n",
    "# Ensure PostGIS extension is enabled\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS postgis\"))\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS gemeinden CASCADE\"))\n",
    "    conn.commit()\n",
    "\n",
    "# Upload to PostGIS with correct WGS84 SRID\n",
    "gdf.to_postgis(\n",
    "    \"gemeinden\",\n",
    "    engine,\n",
    "    if_exists=\"replace\",\n",
    "    index=False,\n",
    "    dtype={\"geometry\": Geometry(\"MULTIPOLYGON\", srid=4326)}  # ✅ Fix here\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8831f7a4",
   "metadata": {},
   "source": [
    "# Create Materialized View for Joined Data\n",
    "This cell creates a materialized view in the database by joining the geometry and cleaned attribute tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b4f8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.DuplicateColumn) column \"geometry\" specified more than once\n\n[SQL: \nDROP MATERIALIZED VIEW IF EXISTS gemeinden_merged;\nCREATE MATERIALIZED VIEW gemeinden_merged AS\nSELECT \n    g.*, \n    c.*, \n    g.geometry::geometry AS geometry\nFROM \n    gemeinden g\nJOIN \n    gemeinden_cleaned c\nON \n    g.\"BFS\" = c.\"BFS_NR\";\n]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDuplicateColumn\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spunk\\OneDrive\\Janosh\\ZHAW\\Module\\Semester 8\\Geo_Marketing\\Project\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1964\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1963\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1965\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1966\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spunk\\OneDrive\\Janosh\\ZHAW\\Module\\Semester 8\\Geo_Marketing\\Project\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:945\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mDuplicateColumn\u001b[39m: column \"geometry\" specified more than once\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Execute the SQL\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m engine.connect() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_view_sql\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     conn.commit()\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Materialized view \u001b[39m\u001b[33m'\u001b[39m\u001b[33mgemeinden_merged\u001b[39m\u001b[33m'\u001b[39m\u001b[33m created successfully.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spunk\\OneDrive\\Janosh\\ZHAW\\Module\\Semester 8\\Geo_Marketing\\Project\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1416\u001b[39m, in \u001b[36mConnection.execute\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1414\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1417\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1420\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spunk\\OneDrive\\Janosh\\ZHAW\\Module\\Semester 8\\Geo_Marketing\\Project\\.venv\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:523\u001b[39m, in \u001b[36mClauseElement._execute_on_connection\u001b[39m\u001b[34m(self, connection, distilled_params, execution_options)\u001b[39m\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m    522\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    527\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spunk\\OneDrive\\Janosh\\ZHAW\\Module\\Semester 8\\Geo_Marketing\\Project\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1638\u001b[39m, in \u001b[36mConnection._execute_clauseelement\u001b[39m\u001b[34m(self, elem, distilled_parameters, execution_options)\u001b[39m\n\u001b[32m   1626\u001b[39m compiled_cache: Optional[CompiledCacheType] = execution_options.get(\n\u001b[32m   1627\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompiled_cache\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.engine._compiled_cache\n\u001b[32m   1628\u001b[39m )\n\u001b[32m   1630\u001b[39m compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(\n\u001b[32m   1631\u001b[39m     dialect=dialect,\n\u001b[32m   1632\u001b[39m     compiled_cache=compiled_cache,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1636\u001b[39m     linting=\u001b[38;5;28mself\u001b[39m.dialect.compiler_linting | compiler.WARN_LINTING,\n\u001b[32m   1637\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1638\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1639\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1640\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1646\u001b[39m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[32m   1651\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_execute(\n\u001b[32m   1652\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1653\u001b[39m         elem,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1657\u001b[39m         ret,\n\u001b[32m   1658\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spunk\\OneDrive\\Janosh\\ZHAW\\Module\\Semester 8\\Geo_Marketing\\Project\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1843\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exec_insertmany_context(dialect, context)\n\u001b[32m   1842\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[32m   1845\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spunk\\OneDrive\\Janosh\\ZHAW\\Module\\Semester 8\\Geo_Marketing\\Project\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1983\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1980\u001b[39m     result = context._setup_result_proxy()\n\u001b[32m   1982\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1983\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1984\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spunk\\OneDrive\\Janosh\\ZHAW\\Module\\Semester 8\\Geo_Marketing\\Project\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2352\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[39m\n\u001b[32m   2350\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[32m   2351\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2352\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2353\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2354\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spunk\\OneDrive\\Janosh\\ZHAW\\Module\\Semester 8\\Geo_Marketing\\Project\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1964\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1962\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1963\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1965\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1966\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n\u001b[32m   1969\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_cursor_execute(\n\u001b[32m   1970\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1971\u001b[39m         cursor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1975\u001b[39m         context.executemany,\n\u001b[32m   1976\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\spunk\\OneDrive\\Janosh\\ZHAW\\Module\\Semester 8\\Geo_Marketing\\Project\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:945\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mProgrammingError\u001b[39m: (psycopg2.errors.DuplicateColumn) column \"geometry\" specified more than once\n\n[SQL: \nDROP MATERIALIZED VIEW IF EXISTS gemeinden_merged;\nCREATE MATERIALIZED VIEW gemeinden_merged AS\nSELECT \n    g.*, \n    c.*, \n    g.geometry::geometry AS geometry\nFROM \n    gemeinden g\nJOIN \n    gemeinden_cleaned c\nON \n    g.\"BFS\" = c.\"BFS_NR\";\n]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(local_db_url)\n",
    "\n",
    "# Define and run SQL for creating a materialized view with the join\n",
    "create_view_sql = \"\"\"\n",
    "DROP MATERIALIZED VIEW IF EXISTS gemeinden_merged;\n",
    "CREATE MATERIALIZED VIEW gemeinden_merged AS\n",
    "SELECT \n",
    "    g.*,\n",
    "    c.*\n",
    "FROM \n",
    "    gemeinden g\n",
    "JOIN \n",
    "    gemeinden_cleaned c\n",
    "ON \n",
    "    g.\"BFS\" = c.\"BFS_NR\";\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_view_sql))\n",
    "    conn.commit()\n",
    "\n",
    "print(\"✅ Materialized view 'gemeinden_merged' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8e49fa",
   "metadata": {},
   "source": [
    "# Export Local Queries as GEOJSON (NOT NEEDED ONLY FOR TESTING!)\n",
    "This section defines a function to export selected KPIs for a given year as GeoJSON files for use in the frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3988cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "# DB connection\n",
    "engine = create_engine(local_db_url)\n",
    "\n",
    "\n",
    "def export_geojson(kpi_column: str, year: int):\n",
    "    filename = f\"geo_kpi_{kpi_column}_{year}.geojson\"\n",
    "    output_dir = \"Frontend/geomarketing-map/public/data\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    path = os.path.join(output_dir, filename)\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT \"BFS\", \"GEBIET_NAME\", \"{kpi_column}\", \"Year\", geometry\n",
    "    FROM gemeinden_merged\n",
    "    WHERE \"Year\" = {year}\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_postgis(query, engine, geom_col=\"geometry\")\n",
    "    gdf = gdf.to_crs(epsg=4326)  # Ensure WGS84 for Leaflet\n",
    "\n",
    "    gdf.to_file(path, driver=\"GeoJSON\")\n",
    "    print(f\"✅ Exported {kpi_column} for {year} → {path}\")\n",
    "\n",
    "# Example usage\n",
    "export_geojson(\"Gesundheitsaufwand pro Einwohner\", 2020)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af44832",
   "metadata": {},
   "source": [
    "# Spatial Autocorrelation (Moran's I) for 2020 (NOT NEEDED ONLY FOR TESTING!)\n",
    "This cell calculates and visualizes the spatial autocorrelation (Moran's I) for all KPI columns for the year 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541888fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from libpysal.weights import Queen\n",
    "from esda.moran import Moran\n",
    "\n",
    "# Load your data for a given year\n",
    "gdf = gpd.read_postgis(\n",
    "    'SELECT * FROM gemeinden_merged WHERE \"Year\" = 2020',\n",
    "    engine,\n",
    "    geom_col=\"geometry\"\n",
    ")\n",
    "\n",
    "# Create spatial weights once\n",
    "w = Queen.from_dataframe(gdf)\n",
    "w.transform = 'r'\n",
    "\n",
    "# Non-KPI columns to exclude\n",
    "non_kpi_cols = {\n",
    "    \"BFS\", \"BFS_NR\", \"GEBIET_NAME\", \"Year\", \"geometry\",\n",
    "    \"BEZIRKSNAM\", \"ART_TEXT\", \"ART_CODE\", \"GEMEINDENA\",\n",
    "    \"ARPS\", \"SHAPE_AREA\", \"SHAPE_LEN\", \"AREA_ROUND\"\n",
    "}\n",
    "\n",
    "# Detect KPI columns\n",
    "kpi_columns = [col for col in gdf.columns if col not in non_kpi_cols and gdf[col].dtype in ['float64', 'int64']]\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "\n",
    "for kpi in kpi_columns:\n",
    "    cleaned = gdf.dropna(subset=[kpi])\n",
    "    if cleaned.empty: continue\n",
    "    try:\n",
    "        mi = Moran(cleaned[kpi].values, Queen.from_dataframe(cleaned))\n",
    "        results.append({\n",
    "            \"KPI\": kpi,\n",
    "            \"Moran_I\": mi.I,\n",
    "            \"p_value\": mi.p_sim\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error for {kpi}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "moran_df = pd.DataFrame(results).sort_values(\"Moran_I\", ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.barh(moran_df[\"KPI\"], moran_df[\"Moran_I\"], color=[\"#2ca02c\" if p < 0.05 else \"#cccccc\" for p in moran_df[\"p_value\"]])\n",
    "plt.axvline(0, color=\"black\", linewidth=0.8)\n",
    "plt.xlabel(\"Moran's I (2020)\")\n",
    "plt.title(\"Spatial Autocorrelation by KPI (Moran's I)\")\n",
    "plt.tight_layout()\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efb44ad",
   "metadata": {},
   "source": [
    "# Moran's I Analysis Across All Years (Dauer je nach Datenmenge 5 min +)\n",
    "This cell loops through all years, calculates Moran's I for each KPI, and saves the results for further analysis or frontend use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e151979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from libpysal.weights import Queen\n",
    "from esda.moran import Moran\n",
    "\n",
    "years = range(1990, 2023)\n",
    "results = []\n",
    "\n",
    "# Columns to ignore (non-KPIs)\n",
    "non_kpi_cols = {\n",
    "    \"BFS\", \"BFS_NR\", \"GEBIET_NAME\", \"Year\", \"geometry\",\n",
    "    \"BEZIRKSNAM\", \"ART_TEXT\", \"ART_CODE\", \"GEMEINDENA\",\n",
    "    \"ARPS\", \"SHAPE_AREA\", \"SHAPE_LEN\", \"AREA_ROUND\"\n",
    "}\n",
    "\n",
    "for year in years:\n",
    "    print(f\"📅 Processing year: {year}\")\n",
    "    try:\n",
    "        gdf = gpd.read_postgis(\n",
    "            f'SELECT * FROM gemeinden_merged WHERE \"Year\" = {year}',\n",
    "            engine,\n",
    "            geom_col=\"geometry\"\n",
    "        )\n",
    "\n",
    "        if gdf.empty:\n",
    "            continue\n",
    "\n",
    "        w = Queen.from_dataframe(gdf)\n",
    "        w.transform = 'r'\n",
    "\n",
    "        kpi_columns = [col for col in gdf.columns if col not in non_kpi_cols and gdf[col].dtype in ['float64', 'int64']]\n",
    "\n",
    "        for kpi in kpi_columns:\n",
    "            cleaned = gdf.dropna(subset=[kpi])\n",
    "            if cleaned.empty:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                mi = Moran(cleaned[kpi].values, Queen.from_dataframe(cleaned))\n",
    "                results.append({\n",
    "                    \"Year\": year,\n",
    "                    \"KPI\": kpi,\n",
    "                    \"Moran_I\": round(mi.I, 4),\n",
    "                    \"p_value\": round(mi.p_sim, 4)\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error in {year} for {kpi}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not load year {year}: {e}\")\n",
    "\n",
    "# Save to CSV or JSON for frontend\n",
    "df_result = pd.DataFrame(results)\n",
    "df_result.to_csv(\"Frontend/geomarketing-map/public/data/moran_results.csv\", index=False)\n",
    "df_result.to_json(\"Frontend/geomarketing-map/public/data/moran_results.json\", orient=\"records\")\n",
    "\n",
    "print(\"✅ Finished Moran's I analysis across all years.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c33a25d",
   "metadata": {},
   "source": [
    "# Export Static Geometry as GeoJSON\n",
    "This cell exports the static geometry of municipalities as a GeoJSON file for use in the frontend mapping application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acd7d807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exported static geometry to Frontend/geomarketing-map/public/data/gemeinden_geometry.geojson\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Path to your shapefile\n",
    "shp_path = \"Gemeindegrenzen/UP_GEMEINDEN_F.shp\"  # adjust as needed\n",
    "\n",
    "# Load shapefile\n",
    "gdf = gpd.read_file(shp_path)\n",
    "\n",
    "# Simplify: keep only essential columns\n",
    "gdf = gdf[[\"BFS\", \"GEMEINDENA\", \"geometry\"]]  # adjust if your column names differ\n",
    "\n",
    "# Convert to WGS84 for frontend mapping (Leaflet uses EPSG:4326)\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Export to GeoJSON\n",
    "output_path = \"Frontend/geomarketing-map/public/data/gemeinden_geometry.geojson\"\n",
    "gdf.to_file(output_path, driver=\"GeoJSON\")\n",
    "\n",
    "print(f\"✅ Exported static geometry to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f02e753",
   "metadata": {},
   "source": [
    "# Database Dump and Restore to Neon\n",
    "This cell provides a script to dump the local database and restore it to a remote Neon database using environment variables for credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b22a3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Creating dump: geomarketing_2025-04-24.bak\n",
      "✅ Dump created\n",
      "🔁 Restoring to Neon...\n",
      "✅ Restore complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import subprocess\n",
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# === CONFIG ===\n",
    "LOCAL_DB_URL = os.getenv(\"LOCAL_DB_URL\")  # e.g. postgresql://postgres:password@localhost:5432/geomarketing\n",
    "NEON_CONNECTION = os.getenv(\"NEON_CONNECTION_STRING\")  # e.g. postgresql://user:pw@host/db?sslmode=require\n",
    "DUMP_FILE = f\"geomarketing_{datetime.date.today()}.bak\"\n",
    "\n",
    "if not LOCAL_DB_URL:\n",
    "    print(\"❌ LOCAL_DB_URL not set in .env file\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if not NEON_CONNECTION:\n",
    "    print(\"❌ NEON_CONNECTION_STRING not set in .env file\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# === STEP 1: Create Dump from Local ===\n",
    "def create_local_dump():\n",
    "    print(f\"📦 Creating dump: {DUMP_FILE}\")\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            \"pg_dump\",\n",
    "            \"--no-owner\",\n",
    "            \"--no-privileges\",\n",
    "            \"--no-publications\",\n",
    "            \"--no-subscriptions\",\n",
    "            \"--no-tablespaces\",\n",
    "            \"-Fc\",\n",
    "            \"-v\",\n",
    "            \"-d\", LOCAL_DB_URL,\n",
    "            \"-f\", DUMP_FILE\n",
    "        ], check=True)\n",
    "        print(\"✅ Dump created\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"❌ pg_dump failed:\")\n",
    "        print(e.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "# === STEP 2: Restore to Neon ===\n",
    "def restore_to_neon():\n",
    "    print(\"🔁 Restoring to Neon...\")\n",
    "    try:\n",
    "        result = subprocess.run([\n",
    "            \"pg_restore\",\n",
    "            \"--verbose\",\n",
    "            \"--clean\",\n",
    "            \"--if-exists\",\n",
    "            \"--no-owner\",\n",
    "            \"-d\", NEON_CONNECTION,\n",
    "            DUMP_FILE\n",
    "        ], check=True, capture_output=True, text=True)\n",
    "        print(\"✅ Restore complete\")\n",
    "        print(result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"❌ pg_restore failed:\")\n",
    "        print(e.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "# === MAIN ===\n",
    "if __name__ == \"__main__\":\n",
    "    create_local_dump()\n",
    "    restore_to_neon()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
